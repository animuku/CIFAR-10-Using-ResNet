{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageRecognition.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/animuku/CIFAR-10-Using-ResNet/blob/master/ImageRecognition.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "LJGJmNxbp7Cx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "922a98c4-22a0-4a49-d536-a332b02d5070"
      },
      "cell_type": "code",
      "source": [
        "!wget -c https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-08-20 14:52:37--  https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170498071 (163M) [application/x-gzip]\n",
            "Saving to: ‘cifar-10-python.tar.gz’\n",
            "\n",
            "cifar-10-python.tar 100%[===================>] 162.60M  2.03MB/s    in 54s     \n",
            "\n",
            "2018-08-20 14:53:31 (3.04 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "stRwyt2CqBpS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "81258ebd-e3c5-4e5a-e62f-a9481ebbb71a"
      },
      "cell_type": "code",
      "source": [
        "!tar xvzf cifar-10-python.tar.gz\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cifar-10-batches-py/\r\n",
            "cifar-10-batches-py/data_batch_4\n",
            "cifar-10-batches-py/readme.html\n",
            "cifar-10-batches-py/test_batch\n",
            "cifar-10-batches-py/data_batch_3\n",
            "cifar-10-batches-py/batches.meta\n",
            "cifar-10-batches-py/data_batch_2\n",
            "cifar-10-batches-py/data_batch_5\n",
            "cifar-10-batches-py/data_batch_1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JaZqub95qB50",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "82dff979-e142-4fbf-cd01-8385eab5c116"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.layers import *\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras import backend as K\n",
        "K.set_image_dim_ordering('th')\n",
        "print(keras.__version__)\n",
        "\n",
        "\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R8m-2Wt1xPW2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_size = 32\n",
        "num_channels=3\n",
        "img_size_flat = img_size * img_size * num_channels\n",
        "num_classes = 10\n",
        "num_files_train = 5\n",
        "num_images_file=10000\n",
        "num_images_train=num_files_train*num_images_file\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T770m3LC1ctM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d5y3cCXW1f5K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convert_images(raw):\n",
        "    raw_float=np.array(raw,dtype=float)/255.0\n",
        "    images=raw_float.reshape([-1,num_channels,img_size,img_size])\n",
        "    images = images.transpose([0, 2, 3, 1])\n",
        "    return images\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cq3s7SE-1h-X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data(filename):\n",
        "    data=unpickle(filename)\n",
        "    raw_images=data[b'data']\n",
        "    cls = np.array(data[b'labels'])\n",
        "    \n",
        "    images=convert_images(raw_images)\n",
        "    return images,cls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HzkciAB41kUB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_training_data():\n",
        "    images=np.zeros(shape=[num_images_train,img_size,img_size,num_channels],dtype=float)\n",
        "    classes=np.zeros(shape=[num_images_train],dtype=int)\n",
        "    \n",
        "    begin=0\n",
        "    \n",
        "    for i in range(num_files_train):\n",
        "        images_batch, cls_batch = load_data(filename='cifar-10-batches-py/data_batch_' + str(i + 1))\n",
        "        \n",
        "        num_images=len(images_batch)\n",
        "        end=begin+num_images\n",
        "        \n",
        "        images[begin:end,:]=images_batch\n",
        "        classes[begin:end]=cls_batch\n",
        "        \n",
        "        begin=end\n",
        "        \n",
        "        return images, classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hLAwd_ffkORX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_test_data():\n",
        "    images, cls = load_data(filename=\"cifar-10-batches-py/test_batch\")\n",
        "    return images,cls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G6brP1u41ss6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a2500c21-5670-44ea-803d-631476223a2a"
      },
      "cell_type": "code",
      "source": [
        "images,classes=load_training_data()\n",
        "classes=to_categorical(classes,10)\n",
        "print(images.shape)\n",
        "\n",
        "test_images,test_classes=load_test_data()\n",
        "test_classes=to_categorical(test_classes,10)\n",
        "print(classes.shape)\n"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(50000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zNVeHcx_1vVb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1781
        },
        "outputId": "f91c0aa3-49a5-4742-f3cf-f1a387eeb0e2"
      },
      "cell_type": "code",
      "source": [
        "print (images[2,:,:,:])\n",
        "print(test_images[2,:,:,:])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[1.         1.         1.        ]\n",
            "  [0.99215686 0.99215686 0.99215686]\n",
            "  [0.99215686 0.99215686 0.99215686]\n",
            "  ...\n",
            "  [0.99215686 0.99215686 0.99215686]\n",
            "  [0.99215686 0.99215686 0.99215686]\n",
            "  [0.99215686 0.99215686 0.99215686]]\n",
            "\n",
            " [[1.         1.         1.        ]\n",
            "  [1.         1.         1.        ]\n",
            "  [1.         1.         1.        ]\n",
            "  ...\n",
            "  [1.         1.         1.        ]\n",
            "  [1.         1.         1.        ]\n",
            "  [1.         1.         1.        ]]\n",
            "\n",
            " [[1.         1.         1.        ]\n",
            "  [0.99607843 0.99607843 0.99607843]\n",
            "  [0.99607843 0.99607843 0.99607843]\n",
            "  ...\n",
            "  [0.99607843 0.99607843 0.99607843]\n",
            "  [0.99607843 0.99607843 0.99607843]\n",
            "  [0.99607843 0.99607843 0.99607843]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.44313725 0.47058824 0.43921569]\n",
            "  [0.43529412 0.4627451  0.43529412]\n",
            "  [0.41176471 0.43921569 0.41568627]\n",
            "  ...\n",
            "  [0.28235294 0.31764706 0.31372549]\n",
            "  [0.28235294 0.31372549 0.30980392]\n",
            "  [0.28235294 0.31372549 0.30980392]]\n",
            "\n",
            " [[0.43529412 0.4627451  0.43137255]\n",
            "  [0.40784314 0.43529412 0.40784314]\n",
            "  [0.38823529 0.41568627 0.38431373]\n",
            "  ...\n",
            "  [0.26666667 0.29411765 0.28627451]\n",
            "  [0.2745098  0.29803922 0.29411765]\n",
            "  [0.30588235 0.32941176 0.32156863]]\n",
            "\n",
            " [[0.41568627 0.44313725 0.41176471]\n",
            "  [0.38823529 0.41568627 0.38431373]\n",
            "  [0.37254902 0.4        0.36862745]\n",
            "  ...\n",
            "  [0.30588235 0.33333333 0.3254902 ]\n",
            "  [0.30980392 0.33333333 0.3254902 ]\n",
            "  [0.31372549 0.3372549  0.32941176]]]\n",
            "[[[0.61960784 0.74509804 0.87058824]\n",
            "  [0.61960784 0.73333333 0.85490196]\n",
            "  [0.54509804 0.65098039 0.76078431]\n",
            "  ...\n",
            "  [0.89411765 0.90588235 0.91764706]\n",
            "  [0.92941176 0.9372549  0.95294118]\n",
            "  [0.93333333 0.94509804 0.96470588]]\n",
            "\n",
            " [[0.66666667 0.78431373 0.89803922]\n",
            "  [0.6745098  0.78039216 0.88627451]\n",
            "  [0.59215686 0.69019608 0.78823529]\n",
            "  ...\n",
            "  [0.90980392 0.90980392 0.9254902 ]\n",
            "  [0.96470588 0.96470588 0.98039216]\n",
            "  [0.96470588 0.96862745 0.98431373]]\n",
            "\n",
            " [[0.68235294 0.78823529 0.88235294]\n",
            "  [0.69019608 0.78431373 0.87058824]\n",
            "  [0.61568627 0.70196078 0.78039216]\n",
            "  ...\n",
            "  [0.90196078 0.89803922 0.90980392]\n",
            "  [0.98039216 0.97647059 0.98431373]\n",
            "  [0.96078431 0.95686275 0.96862745]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.12156863 0.15686275 0.17647059]\n",
            "  [0.11764706 0.15294118 0.17254902]\n",
            "  [0.10196078 0.1372549  0.15686275]\n",
            "  ...\n",
            "  [0.14509804 0.15686275 0.18039216]\n",
            "  [0.03529412 0.05098039 0.05490196]\n",
            "  [0.01568627 0.02745098 0.01960784]]\n",
            "\n",
            " [[0.09019608 0.13333333 0.15294118]\n",
            "  [0.10588235 0.14901961 0.16862745]\n",
            "  [0.09803922 0.14117647 0.16078431]\n",
            "  ...\n",
            "  [0.0745098  0.07843137 0.09411765]\n",
            "  [0.01568627 0.02352941 0.01176471]\n",
            "  [0.01960784 0.02745098 0.01176471]]\n",
            "\n",
            " [[0.10980392 0.16078431 0.18431373]\n",
            "  [0.11764706 0.16862745 0.19607843]\n",
            "  [0.1254902  0.17647059 0.20392157]\n",
            "  ...\n",
            "  [0.01960784 0.02352941 0.03137255]\n",
            "  [0.01568627 0.01960784 0.01176471]\n",
            "  [0.02745098 0.03137255 0.02745098]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nv1_UbkN2UpB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def identity_block(X,f,filters):\n",
        "    F1,F2,F3=filters\n",
        "    \n",
        "    X_shortcut=X\n",
        "    \n",
        "    X=Conv2D(filters=F1,kernel_size=(1,1),strides=(1,1),padding='valid')(X)\n",
        "    X=BatchNormalization(axis=3)(X)\n",
        "    X=Activation('relu')(X)\n",
        "    \n",
        "    X=Conv2D(filters=F2,kernel_size=(f,f),strides=(1,1),padding='same')(X)\n",
        "    X=BatchNormalization(axis=3)(X)\n",
        "    X=Activation('relu')(X)\n",
        "    \n",
        "    X=Conv2D(filters=F3,kernel_size=(1,1),strides=(1,1),padding='valid')(X)\n",
        "    X=BatchNormalization(axis=3)(X)\n",
        "    \n",
        "    \n",
        "    X=Add()([X,X_shortcut])\n",
        "    \n",
        "    X=Activation('relu')(X)\n",
        "    \n",
        "    return X   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VsK0wnqK2ZSt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convolutional_block(X,f,filters,s=2):\n",
        "    F1,F2,F3=filters\n",
        "    \n",
        "    X_shortcut=X\n",
        "    \n",
        "    X=Conv2D(filters=F1,kernel_size=(1,1),strides=(s,s))(X)\n",
        "    X=BatchNormalization(axis=3)(X)\n",
        "    X=Activation('relu')(X)\n",
        "    \n",
        "    X=Conv2D(filters=F2,kernel_size=(f,f),strides=(1,1),padding='same')(X)\n",
        "    X=BatchNormalization(axis=3)(X)\n",
        "    X=Activation('relu')(X)\n",
        "    \n",
        "    X=Conv2D(filters=F3,kernel_size=(1,1),strides=(1,1),padding='valid')(X)\n",
        "    X=BatchNormalization(axis=3)(X)\n",
        "    \n",
        "    \n",
        "    X_shortcut=Conv2D(filters=F3,kernel_size=(1,1),strides=(s,s),padding='valid')(X_shortcut)\n",
        "    X_shortut=BatchNormalization(axis=3)(X_shortcut)\n",
        "    \n",
        "    X=Add()([X,X_shortcut])\n",
        "    \n",
        "    X=Activation('relu')(X)\n",
        "    \n",
        "    return X   \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jwfB3WB72dio",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ResNet50(input_shape = (32, 32, 3), classes = 10):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2),padding='same',name = 'conv1')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2),dim_ordering=\"th\")(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256],s=1)\n",
        "    X = identity_block(X, 3, [64, 64, 256])\n",
        "    X = identity_block(X, 3, [64, 64, 256])\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X,f=3,filters=[128,128,512],s=2)\n",
        "    X = identity_block(X,3,[128,128,512])\n",
        "    X = identity_block(X,3,[128,128,512])\n",
        "    X = identity_block(X,3,[128,128,512])\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X,f=3,filters=[256,256,1024],s=2)\n",
        "    X = identity_block(X,3,[256,256,1024])\n",
        "    X = identity_block(X,3,[256,256,1024])\n",
        "    X = identity_block(X,3,[256,256,1024])\n",
        "    X = identity_block(X,3,[256,256,1024])\n",
        "    X = identity_block(X,3,[256,256,1024])\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X,f=3,filters=[512,512,2048],s=2)\n",
        "    X = identity_block(X,3,[512,512,2048])\n",
        "    X = identity_block(X,3,[512,512,2048])\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D(pool_size=(2,2),name='avg_pool',padding='same')(X)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax')(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jfN2ZnKuGZgB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "8bb0d3b4-90f4-4d5a-a3d6-139f032ff437"
      },
      "cell_type": "code",
      "source": [
        "model=ResNet50(input_shape=(32,32,3),classes=10)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((3, 3), strides=(2, 2), data_format=\"channels_first\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "QMx7pkz4fRdB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P-_k1E1tj1Ux",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1395
        },
        "outputId": "a8832e70-0da9-446c-cb36-0dbf8237b66e"
      },
      "cell_type": "code",
      "source": [
        "model.fit(images,classes,epochs = 5,batch_size = 32)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 499s 10ms/step - loss: 2.8996 - acc: 0.8201\n",
            "Epoch 2/5\n",
            "15584/50000 [========>.....................] - ETA: 5:43 - loss: 2.9084 - acc: 0.8196"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-7d169743edd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Z-cVrrqBmBaY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6071a8b3-3f0c-46d0-b37b-2ea3c41b3da6"
      },
      "cell_type": "code",
      "source": [
        "preds = model.evaluate(test_images,test_classes)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 14s 1ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ib4FVyu7pBNe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "fb018512-764e-4b22-cf19-818b9d603929"
      },
      "cell_type": "code",
      "source": [
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss = 14.506285661315918\n",
            "Test Accuracy = 0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0fV5VEZPpwof",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}